{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2094f895",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9af34d",
   "metadata": {},
   "source": [
    "This document is part of a project which compares the performance of deep learning models in classificaiton of a disease or disorder using 3D and 2D brain images.\n",
    "In this document, I train models using 2D brain images of people with and without brain tumor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089ebfc5",
   "metadata": {},
   "source": [
    "The data is accessible here: https://www.kaggle.com/datasets/ahmedhamada0/brain-tumor-detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2ae905",
   "metadata": {},
   "source": [
    "The original dataset contains 3000 images. However, to have a closer comparison with the 3D image classification model (which I used 3D autism brain image dataset), I only included 628 images.\n",
    "The subset data was equally distributed between the two classes of the data, that is: \n",
    "\n",
    "- **Tumor**\n",
    "- **No Tumor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0832b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import normalize\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327703e7",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf30a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_directory = ' BrainTumor_subsetData/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9540a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_tumor = os.listdir(image_directory + 'no')\n",
    "yes_tumor = os.listdir(image_directory + 'yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0165b3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(no_tumor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd90496",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c44f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label 0 for no_tumor images\n",
    "for i, image_name in enumerate(no_tumor):\n",
    "    if(image_name.split('.')[1] == 'jpg'):\n",
    "        image = cv2.imread(image_directory + 'no/' + image_name)\n",
    "        image = Image.fromarray(image, 'RGB')\n",
    "        image = image.resize((64,64))\n",
    "        dataset.append(np.array(image))\n",
    "        label.append(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b948dd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label 1 for no_tumor images\n",
    "for i, image_name in enumerate(yes_tumor):\n",
    "    if(image_name.split('.')[1] == 'jpg'):\n",
    "        image = cv2.imread(image_directory + 'yes/' + image_name)\n",
    "        image = Image.fromarray(image, 'RGB')\n",
    "        image = image.resize((64,64))\n",
    "        dataset.append(np.array(image))\n",
    "        label.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6409ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e8093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b867e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99482802",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.array(dataset)\n",
    "label = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c53f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset, label, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aa0fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = normalize(x_train, axis = 1)\n",
    "x_test = normalize(x_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fa409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use when we use categorical crossentropy\n",
    "y_train = to_categorical(y_train, num_classes = 2)\n",
    "y_test = to_categorical(y_test, num_classes = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec79f9cd",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dbea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676d35a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3befa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b31cb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_size = 64 \n",
    "model.add(Conv2D(32, (3,3),input_shape = (64,64, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f10417",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, (3,3),kernel_initializer = 'he_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6e4bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, (3,3),kernel_initializer = 'he_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded513cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(2)) #categorical cross entropy so we use 2\n",
    "model.add(Activation('softmax')) #softmax for categorical entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47730a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a40542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b376861e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "model_train = model.fit(x_train, y_train, batch_size = 10, verbose = 1, epochs = 60, validation_data = (x_test, y_test), \n",
    "          shuffle = False, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95623dda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save('Braintumor_categorical.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44366c6",
   "metadata": {},
   "source": [
    "## Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5107f73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('Braintumor_categorical.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257346ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_image = cv2.imread('Br35H-Brain Tumor Detection 2020/pred/pred8.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f61f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.fromarray(pred_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5b20b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.resize((64,64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5371150a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4721f61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9a5d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = np.expand_dims(img, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199355ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = model.predict(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210ca986",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(result)\n",
    "#the sum shows the sum of the probabilities for both classes will always be 1.0. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a1fdc3",
   "metadata": {},
   "source": [
    "## Testing model's classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63947256",
   "metadata": {},
   "source": [
    "The numbder of test dataset images was 1000 and equally distributed between the two classes. That is:\n",
    "\n",
    "- **Tumor**: 500 images\n",
    "\n",
    "- **No Tumor**: 500 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23ef49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the images\n",
    "data_root = 'BrainTumor_TestDF'  \n",
    "no_tumor_folder = os.path.join(data_root, 'NoTumor')\n",
    "tumor_folder = os.path.join(data_root, 'Tumor')\n",
    "\n",
    "def preprocess_image(image):\n",
    "    img = cv2.resize(image, (64, 64))  # Resize the image\n",
    "    img = normalize(img, axis=1)  # Apply the same normalization as used before training\n",
    "    return img\n",
    "\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "# Load and preprocess no tumor images\n",
    "for image_filename in os.listdir(no_tumor_folder):\n",
    "    image_path = os.path.join(no_tumor_folder, image_filename)\n",
    "    image = cv2.imread(image_path)\n",
    "    preprocessed_image = preprocess_image(image)\n",
    "    test_images.append(preprocessed_image)\n",
    "    test_labels.append(0)  # Label 0 for no tumor\n",
    "\n",
    "# Load and preprocess tumor images\n",
    "for image_filename in os.listdir(tumor_folder):\n",
    "    image_path = os.path.join(tumor_folder, image_filename)\n",
    "    image = cv2.imread(image_path)\n",
    "    preprocessed_image = preprocess_image(image)\n",
    "    test_images.append(preprocessed_image)\n",
    "    test_labels.append(1)  # Label 1 for tumor\n",
    "\n",
    "# Convert test_images and test_labels to numpy arrays\n",
    "test_images = np.array(test_images)\n",
    "test_labels = to_categorical(np.array(test_labels), num_classes=2)  # Convert to one-hot encoded format\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('Braintumor_categorical.h5')  # Replace with the actual path to your model\n",
    "\n",
    "# Make predictions using the model\n",
    "predictions = model.predict(test_images)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(predicted_labels == np.argmax(test_labels, axis=1)) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Print actual and predicted classifications\n",
    "for i in range(len(test_images)):\n",
    "    actual_classification = 'No Tumor' if test_labels[i][0] == 1 else 'Tumor'\n",
    "    predicted_classification = 'No Tumor' if predicted_labels[i] == 0 else 'Tumor'\n",
    "    \n",
    "    print(f\"Image {i+1} - Actual: {actual_classification} - Predicted: {predicted_classification}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f740e95",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8b9ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels.argmax(axis=1), predicted_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae7965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.set(font_scale=1.5)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"RdPu\", xticklabels=[\"No Tumor\", \"Tumor\"], yticklabels=[\"No Tumor\", \"Tumor\"])\n",
    "plt.xlabel(\"Predicted\",  fontsize=14, fontweight='bold')\n",
    "plt.ylabel(\"Actual\",  fontsize=14, fontweight='bold')\n",
    "plt.title(\"Confusion Matrix\",  fontsize=14, fontweight='bold')\n",
    "plt.savefig(\"Tumor_CategoricalClass_Confusion Matrix.png\", dpi = 300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14568eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating classification report\n",
    "class_report = classification_report(np.argmax(test_labels, axis=1), predicted_labels)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b041d912",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = recall_score(test_labels.argmax(axis=1), predicted_labels)\n",
    "precision = precision_score(test_labels.argmax(axis=1), predicted_labels)\n",
    "f1 = f1_score(test_labels.argmax(axis=1), predicted_labels)\n",
    "\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502df544",
   "metadata": {},
   "source": [
    "## Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfc867b",
   "metadata": {},
   "source": [
    "**Accuracy: 92.70%**\n",
    "\n",
    "**Recall: 89%**\n",
    "\n",
    "**Precision: 96%**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
