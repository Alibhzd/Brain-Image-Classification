{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document is part of a project which compares the performance of deep learning models in classificaiton of a disease or disorder using 3D and 2D brain images.\n",
    "In this document, I train models using 3D brain images of people with and without autism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is accessible here: **Autism Brain Imaging Data Exchange 1**: http://fcon_1000.projects.nitrc.org/indi/abide/abide_I.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original dataset contains 1112 images. However, since running models for 3D images require more processing time I had to minimize the data and only included 628 images due to lack computational capacity. \n",
    "The subset data was equally distributed between the two classes of the data, that is: \n",
    "- **Autism**\n",
    "- **NonAutism**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ukNDsYjllqRT",
    "outputId": "b01ad8a1-cfb8-4fc0-d2ea-ddf53ff9af16"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import glob\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input,Dense,Flatten,Dropout,Conv3D,MaxPooling3D,Activation #merge,\n",
    "from keras.models import Model,Sequential,load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras import activations\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as rng\n",
    "import scipy.misc\n",
    "from skimage.transform import resize\n",
    "from PIL import Image\n",
    "import nibabel as nib #reading MR images\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.utils import shuffle\n",
    "import math\n",
    "import glob\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "#!pip install --upgrade scipy==1.2.1 # to fix import imresize error in keras-vis library\n",
    "#!pip install git+https://github.com/raghakot/keras-vis.git --upgrade   # Load Keras-vis library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several medical and academic centers recruited participants. Therefore, after loading images I check the number of images which corresponds to a participant in each center. Note that the main directory has separate Autism and Nonautism folders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def count_nii_files_center(center_folder):\n",
    "    nii_files = glob.glob(os.path.join(center_folder, '**', '*.nii'), recursive=True)\n",
    "    return len(nii_files)\n",
    "\n",
    "main_folder = 'clean_data' \n",
    "\n",
    "autism_folder = os.path.join(main_folder, 'Autism')\n",
    "nonautism_folder = os.path.join(main_folder, 'NonAutism')\n",
    "\n",
    "autism_centers = [f.path for f in os.scandir(autism_folder) if f.is_dir()]\n",
    "nonautism_centers = [f.path for f in os.scandir(nonautism_folder) if f.is_dir()]\n",
    "\n",
    "for center_folder in autism_centers:\n",
    "    nii_count = count_nii_files_center(center_folder)\n",
    "    center_name = os.path.basename(center_folder)\n",
    "    print(f\"Autism - Recruiting Center: {center_name}, Number of .nii files: {nii_count}\")\n",
    "\n",
    "for center_folder in nonautism_centers:\n",
    "    nii_count = count_nii_files_center(center_folder)\n",
    "    center_name = os.path.basename(center_folder)\n",
    "    print(f\"Nonautism - Recruiting Center: {center_name}, Number of .nii files: {nii_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the images' dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare the images for the model We need to ensure that the dimensions of the images are consistent.\n",
    "Therefore, here I check the dimensions. However, the output shows that the dimensions vary across different recruiting centers.\n",
    "The next challenge would be to decide how to address this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_image_dimensions(data_folder):\n",
    "    image_paths = glob.glob(os.path.join(data_folder, '**', '*.nii'), recursive=True)\n",
    "    \n",
    "    for image_path in image_paths:\n",
    "        img = nib.load(image_path).get_fdata()\n",
    "        print(f\"Image: {image_path}, Dimensions: {img.shape}\")\n",
    "\n",
    "#the data folder\n",
    "data_root = 'AutismSubset_data'\n",
    "autism_folder = os.path.join(data_root, 'Autism')\n",
    "nonautism_folder = os.path.join(data_root, 'NonAutism')\n",
    "\n",
    "# Print dimensions of autism images\n",
    "print(\"Autism Images:\")\n",
    "get_image_dimensions(autism_folder)\n",
    "\n",
    "# Print dimensions of nonautism images\n",
    "print(\"NonAutism Images:\")\n",
    "get_image_dimensions(nonautism_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To address the inconsistency of the images' dimensions, here I extract and select some slices from each axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = nib.load(image_path).get_fdata()\n",
    "    \n",
    "    # Extract middle slices along y-axis\n",
    "    img = img[30:110,60:126,60:126]\n",
    "        \n",
    "    # Z-score Standardization\n",
    "    mean = img.mean()\n",
    "    std = img.std()\n",
    "    img = (img - mean) / std\n",
    "    \n",
    "    return img\n",
    "\n",
    "def load_images_and_labels(data_folder, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "# Specify the subfolder name\n",
    "    target_subfolder = 'anat_1'\n",
    "    \n",
    "    # selecting the target '.nii' files.\n",
    "    pattern = os.path.join(data_folder, '**', target_subfolder, 'mprage.nii')\n",
    "    \n",
    "    # Getting the list of .nii files in the specified subfolder\n",
    "    image_paths = glob.glob(pattern, recursive=True)\n",
    "    \n",
    "    for image_path in image_paths:\n",
    "        img = preprocess_image(image_path)\n",
    "        images.append(img)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "# Preparing the data\n",
    "data_root =  'AutismSubset_data'     \n",
    "autism_folder = os.path.join(data_root, 'Autism')\n",
    "nonautism_folder = os.path.join(data_root, 'NonAutism')\n",
    "\n",
    "# Load autism images\n",
    "autism_images, autism_labels = load_images_and_labels(autism_folder, 1)\n",
    "print(\"Autism Images Length:\", len(autism_images))\n",
    "\n",
    "# Print dimensions of each autism image\n",
    "for i, img in enumerate(autism_images):\n",
    "    print(f\"Autism Image {i + 1} Dimensions: {img.shape}\")\n",
    "\n",
    "\n",
    "# Load nonautism images\n",
    "nonautism_images, nonautism_labels = load_images_and_labels(nonautism_folder, 0)\n",
    "print(\"Nonautism Images Length:\", len(nonautism_images))\n",
    "\n",
    "# Print dimensions of each nonautism image\n",
    "for i, img in enumerate(nonautism_images):\n",
    "    print(f\"Nonautism Image {i + 1} Dimensions: {img.shape}\")\n",
    "\n",
    "\n",
    "# Combine the data and labels\n",
    "images = np.concatenate((autism_images, nonautism_images), axis=0)\n",
    "labels = autism_labels + nonautism_labels\n",
    "\n",
    "# Convert to numpy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "labels = to_categorical(labels)  # Convert labels to one-hot encoded format\n",
    "\n",
    "\n",
    "print(\"Images Shape:\", images.shape)\n",
    "print(\"Labels Shape:\", labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VYL3AngynWGf"
   },
   "outputs": [],
   "source": [
    "# Test-train split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(images, labels, test_size=0.2, stratify=labels, random_state=42) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D Convolutional Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "acS31ohKngN0"
   },
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 10 \n",
    "epochs = 100 \n",
    "input_img = Input(shape = (80, 66, 66, 1))\n",
    "\n",
    "def model(input_img):\n",
    "    conv1 = Conv3D(5, (3, 3, 3), padding='same')(input_img) \n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = MaxPooling3D(pool_size=(2, 2, 2))(conv1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "    conv1 = Dropout(rate = 0.5)(conv1)\n",
    "    \n",
    "    conv2 = Conv3D(5, (3, 3, 3), padding='same',activation='relu')(conv1) \n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = MaxPooling3D(pool_size=(2, 2, 2))(conv2) \n",
    "    conv2 = Activation('relu')(conv2)\n",
    "    conv2 = Dropout(rate = 0.5)(conv2)\n",
    "    \n",
    "    conv3 = Conv3D(5, (3, 3, 3), padding='same',activation='relu')(conv2) \n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = MaxPooling3D(pool_size=(2, 2, 2))(conv3) \n",
    "    conv3 = Activation('relu')(conv3)\n",
    "    conv3 = Dropout(rate=0.5)(conv3)\n",
    "    \n",
    "    conv3 = Flatten()(conv3)\n",
    "\n",
    "    dense = Dense(2, activation='softmax')(conv3) \n",
    "    return dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "colab_type": "code",
    "id": "lSskfEZaIn_C",
    "outputId": "b78e9ab2-1fb5-4ce4-c741-c52d650810d2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "model = Model(input_img, model(input_img))\n",
    "model.compile(loss='categorical_crossentropy', optimizer = Adam(learning_rate), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create an instance of EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "e5CY_HO0I3La",
    "outputId": "e29e7baf-65fe-4239-a55d-ac877d683760"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# fit model\n",
    "model_train = model.fit(train_X, train_y, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_y), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fqfHM3MdTZ-I",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#save model\n",
    "model.save('Autism_model.h5')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "3DKerasAttempt.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
